{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24Nhp-q03zMY",
        "outputId": "9020a649-2174-488a-c957-aaca6ff0b798"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.15.1+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.9/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch) (3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch) (3.10.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (16.0.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (3.7.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.22.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (8.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (5.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (23.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (4.39.3)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.0.7)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-msssim\n",
            "  Downloading pytorch_msssim-0.2.1-py3-none-any.whl (7.2 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from pytorch-msssim) (2.0.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch->pytorch-msssim) (3.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch->pytorch-msssim) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->pytorch-msssim) (4.5.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch->pytorch-msssim) (2.0.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch->pytorch-msssim) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch->pytorch-msssim) (3.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->pytorch-msssim) (16.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->pytorch-msssim) (3.25.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch->pytorch-msssim) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch->pytorch-msssim) (1.3.0)\n",
            "Installing collected packages: pytorch-msssim\n",
            "Successfully installed pytorch-msssim-0.2.1\n"
          ]
        }
      ],
      "source": [
        "! pip3 install torch torchvision torchaudio\n",
        "! pip3 install numpy\n",
        "! pip3  install matplotlib\n",
        "! pip install pytorch-msssim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4RQqM-2I4T6m"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch import nn, optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "from MS_SSIM_L1_loss import MS_SSIM_L1_LOSS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fUxjIvyu4iXT"
      },
      "outputs": [],
      "source": [
        "# Define the autoencoder architecture\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "\n",
        "        # Activation functions\n",
        "        self.relu = nn.ReLU()\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "        # Encoder\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            3, 32, kernel_size=3, stride=1, padding=1\n",
        "        )  # 96*192 -> 96*192\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            32, 64, kernel_size=3, stride=1, padding=1\n",
        "        )  # 96*192 -> 96*192\n",
        "        self.conv3 = nn.Conv2d(\n",
        "            64, 128, kernel_size=4, stride=2, padding=1\n",
        "        )  # 96*192 -> 48*96\n",
        "        self.conv4 = nn.Conv2d(\n",
        "            128, 64, kernel_size=4, stride=2, padding=1\n",
        "        )  # 48*96 -> 24*48\n",
        "        self.conv5 = nn.Conv2d(\n",
        "            64, 8, kernel_size=4, stride=2, padding=1\n",
        "        )  # 24*48 -> 12*24\n",
        "        self.encoder = nn.Sequential(\n",
        "            self.conv1,\n",
        "            self.relu,\n",
        "            self.conv2,\n",
        "            self.relu,\n",
        "            self.conv3,\n",
        "            self.relu,\n",
        "            self.conv4,\n",
        "            self.relu,\n",
        "            self.conv5,\n",
        "            self.relu,\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.t_conv1 = nn.ConvTranspose2d(\n",
        "            8, 64, kernel_size=4, stride=2, padding=1\n",
        "        )  # 12*24 -> 24*48\n",
        "        self.t_conv2 = nn.ConvTranspose2d(\n",
        "            64, 128, kernel_size=4, stride=2, padding=1\n",
        "        )  # 24*48 -> 48*96\n",
        "        self.t_conv3 = nn.ConvTranspose2d(\n",
        "            128, 64, kernel_size=4, stride=2, padding=1\n",
        "        )  # 48*96 -> 96*192\n",
        "        self.t_conv4 = nn.ConvTranspose2d(\n",
        "            64, 32, kernel_size=3, stride=1, padding=1\n",
        "        )  # 96*192 -> 96*192\n",
        "        self.t_conv5 = nn.ConvTranspose2d(\n",
        "            32, 3, kernel_size=3, stride=1, padding=1\n",
        "        )  # 96*192 -> 96*192\n",
        "        self.decoder = nn.Sequential(\n",
        "            self.t_conv1,\n",
        "            self.relu,\n",
        "            self.t_conv2,\n",
        "            self.relu,\n",
        "            self.t_conv3,\n",
        "            self.relu,\n",
        "            self.t_conv4,\n",
        "            self.relu,\n",
        "            self.t_conv5,\n",
        "            self.tanh,\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "r8MKVQjp4nPr"
      },
      "outputs": [],
      "source": [
        "def grey_to_rgb(img):\n",
        "    if img.shape[0] == 1:\n",
        "        torch.unsqueeze(img, 0)\n",
        "        img = img.repeat(3, 1, 1)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTR5GKRL5IS2",
        "outputId": "66a5ac28-0d34-4d52-a444-90b0f74e2138"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1183006720it [00:21, 54491789.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./DATA/caltech256/256_ObjectCategories.tar to ./DATA/caltech256\n",
            "torch.Size([64, 3, 96, 192]) torch.Size([64])\n",
            "Epoch [1/10], Step [100/383], Loss: 94.8854\n",
            "Epoch [1/10], Step [200/383], Loss: 96.7849\n",
            "Epoch [1/10], Step [300/383], Loss: 99.8552\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Device configuration\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    # Load the dataset\n",
        "    transform = transforms.Compose(\n",
        "        [   transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5,), (0.5,)),\n",
        "            transforms.Resize((96, 192), antialias=True),\n",
        "            transforms.Lambda(grey_to_rgb),\n",
        "        ]\n",
        "    )\n",
        "    trainset = datasets.Caltech256(\n",
        "        \"./DATA\",\n",
        "        download=True,\n",
        "        transform=transform,\n",
        "    )\n",
        "    # random seed and batch size\n",
        "    random_seed = torch.Generator().manual_seed(42)\n",
        "    batch_size = 64\n",
        "    # split train and test\n",
        "    train, test = torch.utils.data.random_split(trainset, [0.8, 0.2], generator=random_seed)\n",
        "    # dataloader\n",
        "    dataloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "    trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "    testloader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=True)\n",
        "    # check the shape of the data\n",
        "    trainiter = iter(trainloader)\n",
        "    img, label = next(trainiter)\n",
        "    print(img.shape, label.shape) # torch.Size([64, 3, 96, 192]) torch.Size([64])\n",
        "    # Setting parameters\n",
        "    model = Autoencoder()\n",
        "    model = model.to(device)\n",
        "    criterion = MS_SSIM_L1_LOSS()\n",
        "    learning_rate = 0.01\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "    epoch = 10\n",
        "    n_total_steps = len(trainloader)\n",
        "    # Training\n",
        "    start_time = time.time()\n",
        "    for e in range(epoch):\n",
        "        for i, (img_in, _) in enumerate(trainloader):\n",
        "            img_in = img_in.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            img_out = model(img_in)\n",
        "            loss = criterion(img_in, img_out)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if (i + 1) % 100 == 0:\n",
        "                print(\n",
        "                    f\"Epoch [{e+1}/{epoch}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}\"\n",
        "                )\n",
        "    print(\"Finished Training in time\", (time.time() - start_time) / 60, \"mins\")\n",
        "    torch.save(model.state_dict(), \"autoencoder_MS_SSIM_L1.pth\") "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
