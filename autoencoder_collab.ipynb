{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24Nhp-q03zMY",
        "outputId": "29b6a8e2-970d-4fa5-df1a-12232916d79f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.15.1+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.9/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch) (3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch) (3.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (16.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (3.7.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (23.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.22.4)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (5.12.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (4.39.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (8.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.0.7)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "! pip3 install torch torchvision torchaudio\n",
        "! pip3 install numpy\n",
        "! pip3  install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4RQqM-2I4T6m"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch import nn, optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "from MS_SSIM_L1_loss import MS_SSIM_L1_LOSS\n",
        "from processing import grey_to_rgb, get_latest_epoch, resume, checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fUxjIvyu4iXT"
      },
      "outputs": [],
      "source": [
        "# Define the autoencoder architecture\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "\n",
        "        # Activation functions\n",
        "        self.relu = nn.LeakyReLU(0.01)\n",
        "        self.tanh = nn.Tanh()\n",
        "        # Encoder\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            3, 32, kernel_size=3, stride=1, padding=1\n",
        "        )  # 96*192 -> 96*192\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            32, 64, kernel_size=3, stride=1, padding=1\n",
        "        )  # 96*192 -> 96*192\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(\n",
        "            64, 128, kernel_size=4, stride=2, padding=1\n",
        "        )  # 96*192 -> 48*96\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.conv4 = nn.Conv2d(\n",
        "            128, 64, kernel_size=4, stride=2, padding=1\n",
        "        )  # 48*96 -> 24*48\n",
        "        self.bn4 = nn.BatchNorm2d(64)\n",
        "        self.conv5 = nn.Conv2d(\n",
        "            64, 8, kernel_size=4, stride=2, padding=1\n",
        "        )  # 24*48 -> 12*24\n",
        "        self.bn5 = nn.BatchNorm2d(8)\n",
        "        self.encoder = nn.Sequential(\n",
        "            self.conv1,\n",
        "            self.bn1,\n",
        "            self.relu,\n",
        "            self.conv2,\n",
        "            self.bn2,\n",
        "            self.relu,\n",
        "            self.conv3,\n",
        "            self.bn3,\n",
        "            self.relu,\n",
        "            self.conv4,\n",
        "            self.bn4,\n",
        "            self.relu,\n",
        "            self.conv5,\n",
        "            self.bn5,\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.t_conv1 = nn.ConvTranspose2d(\n",
        "            8, 64, kernel_size=4, stride=2, padding=1\n",
        "        )  # 12*24 -> 24*48\n",
        "        self.t_conv2 = nn.ConvTranspose2d(\n",
        "            64, 128, kernel_size=4, stride=2, padding=1\n",
        "        )  # 24*48 -> 48*96\n",
        "        self.t_conv3 = nn.ConvTranspose2d(\n",
        "            128, 64, kernel_size=4, stride=2, padding=1\n",
        "        )  # 48*96 -> 96*192\n",
        "        self.t_conv4 = nn.ConvTranspose2d(\n",
        "            64, 32, kernel_size=3, stride=1, padding=1\n",
        "        )  # 96*192 -> 96*192\n",
        "        self.t_conv5 = nn.ConvTranspose2d(\n",
        "            32, 3, kernel_size=3, stride=1, padding=1\n",
        "        )  # 96*192 -> 96*192\n",
        "        self.decoder = nn.Sequential(\n",
        "            self.t_conv1,\n",
        "            self.bn4,\n",
        "            self.relu,\n",
        "            self.t_conv2,\n",
        "            self.bn3,\n",
        "            self.relu,\n",
        "            self.t_conv3,\n",
        "            self.bn2,\n",
        "            self.relu,\n",
        "            self.t_conv4,\n",
        "            self.bn1,\n",
        "            self.relu,\n",
        "            self.t_conv5,\n",
        "            self.tanh,\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTR5GKRL5IS2",
        "outputId": "d9bd2a8a-0e19-46dd-aff6-67ca0a3fcc2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "torch.Size([64, 3, 96, 192]) torch.Size([64])\n",
            "Epoch [21/30], Step [100/383], Loss: 22.0805\n",
            "Epoch [21/30], Step [200/383], Loss: 21.0892\n",
            "Epoch [21/30], Step [300/383], Loss: 19.2891\n",
            "average loss for epoch 21 is 24.9729\n",
            "Epoch [22/30], Step [100/383], Loss: 23.8410\n",
            "Epoch [22/30], Step [200/383], Loss: 25.5521\n",
            "Epoch [22/30], Step [300/383], Loss: 22.2506\n",
            "average loss for epoch 22 is 24.7999\n",
            "Epoch [23/30], Step [100/383], Loss: 22.2470\n",
            "Epoch [23/30], Step [200/383], Loss: 28.0495\n",
            "Epoch [23/30], Step [300/383], Loss: 35.4048\n",
            "average loss for epoch 23 is 25.5806\n",
            "Epoch [24/30], Step [100/383], Loss: 26.4726\n",
            "Epoch [24/30], Step [200/383], Loss: 28.9144\n",
            "Epoch [24/30], Step [300/383], Loss: 23.1316\n",
            "average loss for epoch 24 is 24.7139\n",
            "Epoch [25/30], Step [100/383], Loss: 28.2770\n",
            "Epoch [25/30], Step [200/383], Loss: 28.1668\n",
            "Epoch [25/30], Step [300/383], Loss: 31.9434\n",
            "average loss for epoch 25 is 24.8351\n",
            "Epoch [26/30], Step [100/383], Loss: 19.7379\n",
            "Epoch [26/30], Step [200/383], Loss: 24.0889\n",
            "Epoch [26/30], Step [300/383], Loss: 19.7301\n",
            "average loss for epoch 26 is 24.2675\n",
            "Epoch [27/30], Step [100/383], Loss: 21.1579\n",
            "Epoch [27/30], Step [200/383], Loss: 19.8882\n",
            "Epoch [27/30], Step [300/383], Loss: 24.5864\n",
            "average loss for epoch 27 is 24.0364\n",
            "Epoch [28/30], Step [100/383], Loss: 27.8651\n",
            "Epoch [28/30], Step [200/383], Loss: 24.4739\n",
            "Epoch [28/30], Step [300/383], Loss: 19.9592\n",
            "average loss for epoch 28 is 24.8760\n",
            "Epoch [29/30], Step [100/383], Loss: 19.2124\n",
            "Epoch [29/30], Step [200/383], Loss: 20.9078\n",
            "Epoch [29/30], Step [300/383], Loss: 26.4732\n",
            "average loss for epoch 29 is 23.8637\n",
            "Epoch [30/30], Step [100/383], Loss: 26.7306\n",
            "Epoch [30/30], Step [200/383], Loss: 27.3290\n",
            "Epoch [30/30], Step [300/383], Loss: 26.3148\n",
            "average loss for epoch 30 is 24.2145\n",
            "Finished Training in time 30.68435928026835 mins\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \"\"\"\n",
        "    User Inputs\n",
        "    \"\"\"\n",
        "    #number of epochs for training\n",
        "    num_epoch = 10\n",
        "    # Loading checkpoint\n",
        "    checkpoint_dir = \"./checkpoints\"\n",
        "    loading_epoch = get_latest_epoch(checkpoint_dir)\n",
        "    # batch size\n",
        "    batch_size = 64\n",
        "    \"\"\"\n",
        "    End of User Inputs\n",
        "    \"\"\"\n",
        "    # Load the dataset\n",
        "    transform = transforms.Compose(\n",
        "        [   transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5,), (0.5,)),\n",
        "            transforms.Resize((96, 192), antialias=True),\n",
        "            transforms.Lambda(grey_to_rgb),\n",
        "        ]\n",
        "    )\n",
        "    trainset = datasets.Caltech256(\n",
        "        \"./DATA\",\n",
        "        download=True,\n",
        "        transform=transform,\n",
        "    )\n",
        "    # random seed\n",
        "    random_seed = torch.Generator().manual_seed(42)\n",
        "    # split train and test\n",
        "    train, test = torch.utils.data.random_split(trainset, [0.8, 0.2], generator=random_seed)\n",
        "    # dataloader\n",
        "    dataloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "    trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "    testloader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=True)\n",
        "    # check the shape of the data\n",
        "    trainiter = iter(trainloader)\n",
        "    img, label = next(trainiter)\n",
        "    print(img.shape, label.shape) # torch.Size([64, 3, 96, 192]) torch.Size([64])\n",
        "    \"\"\"\n",
        "    Model params\n",
        "    \"\"\"\n",
        "    model = Autoencoder()\n",
        "    if loading_epoch != 0:\n",
        "        resume(model, f\"{str(checkpoint_dir)}/MS_SSIM_L1-epoch-{str(loading_epoch)}.pth\")\n",
        "    else:\n",
        "        print(\"No checkpoint found, start training from scratch\")\n",
        "        loading_epoch = 0\n",
        "    total_epoch = num_epoch + loading_epoch\n",
        "    # Move to device\n",
        "    model = model.to(device)\n",
        "    # Set parameters\n",
        "    criterion = MS_SSIM_L1_LOSS()\n",
        "    learning_rate = 0.01\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "    # Training\n",
        "    start_time = time.time()\n",
        "    for e in range(loading_epoch+1, total_epoch+1):\n",
        "        epoch_loss = 0\n",
        "        for i, (img_in, _) in enumerate(trainloader):\n",
        "            img_in = img_in.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            img_out = model(img_in)\n",
        "            loss = criterion(img_in, img_out)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "            if (i + 1) % 100 == 0:\n",
        "                print(\n",
        "                    f\"Epoch [{e}/{total_epoch}], Step [{i+1}/{len(trainloader)}], Loss: {loss.item():.4f}\"\n",
        "                )\n",
        "        print(f'average loss for epoch {e} is {epoch_loss/len(trainloader):.4f}')\n",
        "    checkpoint(model, f\"MS_SSIM_L1-epoch-{total_epoch}.pth\")\n",
        "    print(\"Finished Training in time\", (time.time() - start_time) / 60, \"mins\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}